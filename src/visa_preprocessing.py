# -*- coding: utf-8 -*-
"""Visa_Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xfkqmhWr92MsBuokBIXfvJFob3rLJs47
"""

# MODULE 1: Data Collection & Preprocessing
# AI Enabled Visa Status Prediction and Processing Time Estimator

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

pd.set_option('display.max_columns', None)
plt.style.use('seaborn-v0_8-darkgrid')

# Load data
file_path = '/content/drive/MyDrive/Combined_LCA_Disclosure_Data_FY2024.csv'
df = pd.read_csv(file_path)

print(f"Dataset shape: {df.shape}")
print(f"Columns: {list(df.columns)}\n")

print("Dataset Info:")
df.info()

print("\nFirst 5 rows:")
print(df.head())

# Handle missing values
print("\nMissing values per column:")
missing_values = df.isnull().sum()
missing_percentage = (missing_values / len(df)) * 100
missing_df = pd.DataFrame({
    'Missing Values': missing_values,
    'Percentage': missing_percentage
})
print(missing_df[missing_df['Missing Values'] > 0].sort_values('Percentage', ascending=False))

# Fill missing values
for column in df.columns:
    if df[column].isnull().sum() > 0:
        if df[column].dtype in ['int64', 'float64']:
            if df[column].dtype == 'float64' or df[column].nunique() > 10:
                df[column].fillna(df[column].median(), inplace=True)
            else:
                df[column].fillna(df[column].mode()[0], inplace=True)
        elif df[column].dtype == 'object':
            df[column].fillna(df[column].mode()[0], inplace=True)

print(f"\nTotal missing values after handling: {df.isnull().sum().sum()}")

# Convert date columns
date_columns = ['RECEIVED_DATE', 'DECISION_DATE', 'ORIGINAL_CERT_DATE', 'BEGIN_DATE', 'END_DATE']
for col in date_columns:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors='coerce')

print("\nDate columns converted to datetime")

# Calculate processing days
df['processing_days'] = (df['DECISION_DATE'] - df['RECEIVED_DATE']).dt.days

# Remove invalid processing times
negative_days = df[df['processing_days'] < 0].shape[0]
if negative_days > 0:
    df = df[df['processing_days'] >= 0]
    print(f"Removed {negative_days} records with negative processing days")

print(f"\nProcessing days created:")
print(f"  Mean: {df['processing_days'].mean():.2f} days")
print(f"  Median: {df['processing_days'].median():.2f} days")
print(f"  Min: {df['processing_days'].min()} days")
print(f"  Max: {df['processing_days'].max()} days")

# Clean categorical columns
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    if df[col].dtype == 'object':
        df[col] = df[col].astype(str).str.strip()
        df[col] = df[col].str.replace(r'\s+', ' ', regex=True)

print(f"\nCleaned {len(categorical_cols)} categorical columns")

# Create temporal features from RECEIVED_DATE
if 'RECEIVED_DATE' in df.columns and df['RECEIVED_DATE'].dtype == 'datetime64[ns]':
    df['application_year'] = df['RECEIVED_DATE'].dt.year
    df['application_month'] = df['RECEIVED_DATE'].dt.month
    df['application_day'] = df['RECEIVED_DATE'].dt.day
    df['application_weekday'] = df['RECEIVED_DATE'].dt.weekday

    def get_season(month):
        if month in [12, 1, 2]:
            return 'Winter'
        elif month in [3, 4, 5]:
            return 'Spring'
        elif month in [6, 7, 8]:
            return 'Summer'
        else:
            return 'Fall'

    df['application_season'] = df['application_month'].apply(get_season)

    print(f"Created temporal features from RECEIVED_DATE")

# Exploratory Data Analysis
print("\n" + "="*60)
print("EXPLORATORY DATA ANALYSIS")
print("="*60)

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. Distribution of processing days
axes[0, 0].hist(df['processing_days'], bins=50, edgecolor='black', alpha=0.7)
axes[0, 0].set_xlabel('Processing Days')
axes[0, 0].set_ylabel('Frequency')
axes[0, 0].set_title('Distribution of Processing Days')
axes[0, 0].axvline(df['processing_days'].mean(), color='red', linestyle='--')

# 2. Top 10 visa classes
if 'VISA_CLASS' in df.columns:
    top_visa = df['VISA_CLASS'].value_counts().head(10)
    axes[0, 1].bar(top_visa.index, top_visa.values)
    axes[0, 1].set_xlabel('Visa Class')
    axes[0, 1].set_ylabel('Count')
    axes[0, 1].set_title('Top 10 Visa Classes')
    axes[0, 1].tick_params(axis='x', rotation=45)

# 3. Processing time by visa class
if 'VISA_CLASS' in df.columns:
    visa_avg = df.groupby('VISA_CLASS')['processing_days'].mean().sort_values(ascending=False).head(10)
    axes[1, 0].bar(visa_avg.index, visa_avg.values)
    axes[1, 0].set_xlabel('Visa Class')
    axes[1, 0].set_ylabel('Average Processing Days')
    axes[1, 0].set_title('Top 10 Visa Classes by Processing Time')
    axes[1, 0].tick_params(axis='x', rotation=45)

# 4. Case status distribution
if 'CASE_STATUS' in df.columns:
    status_counts = df['CASE_STATUS'].value_counts()
    axes[1, 1].bar(status_counts.index, status_counts.values)
    axes[1, 1].set_xlabel('Case Status')
    axes[1, 1].set_ylabel('Count')
    axes[1, 1].set_title('Case Status Distribution')
    axes[1, 1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# Additional analysis: Processing time by season
if 'application_season' in df.columns:
    seasonal_avg = df.groupby('application_season')['processing_days'].mean()
    print("\nAverage processing time by season:")
    for season, days in seasonal_avg.items():
        print(f"  {season}: {days:.2f} days")

# Save preprocessed data
output_path = '/content/drive/MyDrive/visa_data_preprocessed.csv'
df.to_csv(output_path, index=False)
print(f"\nPreprocessed data saved to: {output_path}")
print(f"Final dataset shape: {df.shape}")